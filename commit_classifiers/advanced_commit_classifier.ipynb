{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"eszz_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sha', 'num_of_insertions', 'num_of_deletions', 'num_of_changed_files',\n",
       "       'day_of_week', 'hour_of_commit', 'solve_time', 'resolution_time',\n",
       "       'solve_res_diff', 'number_of_comments', 'summary', 'description',\n",
       "       'components', 'affects_versions', 'comments', 'number_of_patches',\n",
       "       'patch_size_mean', 'patch_size_variance', 'patch_size_rel_variance',\n",
       "       'filepath_contains_test', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(['summary', 'description', 'comments'], axis=1, inplace=True)\n",
    "df.drop(['comments'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.description.replace(np.nan, \"\", inplace=True)\n",
    "df.summary.replace(np.nan, \"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_regex(rgx, to_sub_string, flag = None):\n",
    "    if flag != None:\n",
    "        compiled_rgx = re.compile(rgx, flags = flag)\n",
    "    else:\n",
    "        compiled_rgx = re.compile(rgx)\n",
    "    substitutes.append((compiled_rgx, to_sub_string))\n",
    "\n",
    "substitutes = []\n",
    "\n",
    "create_regex(r'[\\w\\d_\\-\\.$]+\\(.*\\)', \"METHOD\")\n",
    "\n",
    "create_regex(r'([12]\\d{3}-(0[1-9]|1[0-2])-(0[1-9]|[12]\\d|3[01]))', \"DATE\")\n",
    "\n",
    "create_regex(r'(2[0-3]|[01]?[0-9]):([0-5]?[0-9]):([0-5]?[0-9])(,\\d+)?', \"TIME\")\n",
    "\n",
    "create_regex(r'(https?|ftp):\\/\\/[^\\s/$.?#].[^\\s]*', \"URL\")\n",
    "\n",
    "create_regex(r'\\[.*?\\|?http.*?\\]', \"URL\")\n",
    "\n",
    "create_regex(r'\\s+npe\\s+', ' EXCEPTION ', re.IGNORECASE)\n",
    "\n",
    "create_regex(r'[A-Z]+-\\d+', \"JIRAID\")\n",
    "\n",
    "create_regex(r'file:\\/[^\\s\\n\\t\\r]*', \"FILEPATH\")\n",
    "\n",
    "create_regex(r'\\[.*?file:\\\\\\.*?\\]', \"FILEPATH\")\n",
    "\n",
    "create_regex(r'\\[~.*]', \"USERNAME\")\n",
    "\n",
    "create_regex(r'{code:?.*}[\\s\\S]*?{code}|{noformat}[\\s\\S]*?{noformat}|{{.*?}}', \"CODE\", re.MULTILINE)\n",
    "\n",
    "create_regex(r'\\w*Error[^\\s\\n\\t\\r]*|\\w*error[^\\s\\n\\t\\r]*', 'ERROR')\n",
    "\n",
    "create_regex(r'\\w*Exception[^\\s\\n\\t\\r]*|\\w*exception[^\\s\\n\\t\\r]*', 'EXCEPTION')\n",
    "\n",
    "def apply_rules_to(sentence):\n",
    "    for substitute in substitutes:\n",
    "        sentence = substitute[0].sub(substitute[1], sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.description = df.description.map(apply_rules_to)\n",
    "df.summary = df.summary.map(apply_rules_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(groupby, x):\n",
    "    if isinstance(x, list):\n",
    "        agg = groupby[x]\n",
    "        result = (agg[:,\"count\"] * agg[:,\"mean\"]).sum() / agg[:,\"count\"].sum()\n",
    "        return result\n",
    "#     print(groupby)\n",
    "    return groupby[:,\"mean\"].mean()\n",
    "\n",
    "def multi_value_target_encoding(df, by_labels, on_label, separator):\n",
    "    dummy = df.copy()\n",
    "    results = []\n",
    "    for by in by_labels:\n",
    "        dummy[by] = dummy[by].str.split(separator)\n",
    "        groupby_count_mean = (dummy\n",
    "           .set_index(on_label)[by]\n",
    "           .apply(pd.Series)\n",
    "           .stack()\n",
    "           .reset_index(name=by)  # Reshape the data\n",
    "           .groupby([by])\n",
    "           .label\n",
    "           .apply(lambda x: x.agg(['count', 'mean'])))\n",
    "#         print(groupby_count_mean)\n",
    "\n",
    "        my_func = functools.partial(func, groupby_count_mean)\n",
    "        res = dummy[by].map(my_func).to_numpy()\n",
    "        results.append(res)\n",
    "    return np.vstack(results).T\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blamed commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "blamed_shas = set()\n",
    "with open('blamed_commits.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        blamed_shas.add(line[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = df[df['sha'].isin(blamed_shas)]\n",
    "df = df[~df['sha'].isin(blamed_shas)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['num_of_insertions', 'num_of_deletions', 'num_of_changed_files', \n",
    "                      'day_of_week', 'hour_of_commit', 'solve_time', 'resolution_time', \n",
    "                     'solve_res_diff', 'number_of_comments', 'number_of_patches',\n",
    "                    'patch_size_mean', 'patch_size_variance', 'patch_size_rel_variance', 'filepath_contains_test']\n",
    "text_features = ['summary', 'description']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median'))])\n",
    "text_transformer = Pipeline(steps=[\n",
    "     ('vect', CountVectorizer(tokenizer=wordpunct_tokenize, stop_words=set(stopwords.words('english')),\n",
    "                             ngram_range=(1,1), max_features=10000)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('tsvd', TruncatedSVD(n_components=10))\n",
    " ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)],\n",
    "    remainder='drop')\n",
    "\n",
    "categorical_features = ['components', 'affects_versions']\n",
    "processed_features = numeric_features + categorical_features + 10*['summary'] + 10*['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/minaremeli/virtual_envs/venv_CRA/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'\"] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "X_text_summary = text_transformer.fit_transform(df.summary.to_numpy(), y)\n",
    "X_text_description = text_transformer.fit_transform(df.description.to_numpy(), y)\n",
    "# preprocess X\n",
    "X = preprocessor.fit_transform(X, y)\n",
    "X_categorical = multi_value_target_encoding(df, categorical_features, 'label', ';')\n",
    "X = np.hstack((X,X_categorical,X_text_summary, X_text_description))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV\n",
    "\n",
    "Grid Search + Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "          'max_depth': [2, 3, 4, 5],\n",
    "          'learning_rate': [0.0125, 0.025, 0.05, 0.1], \n",
    "#           'learning_rate': [ 0.05, 0.1, 0.2], \n",
    "          'n_estimators': [100, 200, 300, 400, 500]\n",
    "#             'n_estimators': [100, 150, 200]\n",
    "}\n",
    "gbc = GradientBoostingClassifier()\n",
    "clf = GridSearchCV(gbc, params, cv=StratifiedKFold(n_splits=10, shuffle=True), scoring='recall', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=GradientBoostingClassifier(criterion='friedman_mse',\n",
       "                                                  init=None, learning_rate=0.1,\n",
       "                                                  loss='deviance', max_depth=3,\n",
       "                                                  max_features=None,\n",
       "                                                  max_leaf_nodes=None,\n",
       "                                                  min_impurity_decrease=0.0,\n",
       "                                                  min_impurity_split=None,\n",
       "                                                  min_samples_leaf=1,\n",
       "                                                  min_samples_split...\n",
       "                                                  n_iter_no_change=None,\n",
       "                                                  presort='auto',\n",
       "                                                  random_state=None,\n",
       "                                                  subsample=1.0, tol=0.0001,\n",
       "                                                  validation_fraction=0.1,\n",
       "                                                  verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.0125, 0.025, 0.05, 0.1],\n",
       "                         'max_depth': [2, 3, 4, 5],\n",
       "                         'n_estimators': [100, 200, 300, 400, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='recall', verbose=0)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.153762</td>\n",
       "      <td>0.122710</td>\n",
       "      <td>0.007125</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.0125, 'max_depth': 2, 'n_e...</td>\n",
       "      <td>0.426357</td>\n",
       "      <td>0.461240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472868</td>\n",
       "      <td>0.472868</td>\n",
       "      <td>0.445736</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.486434</td>\n",
       "      <td>0.466019</td>\n",
       "      <td>0.450485</td>\n",
       "      <td>0.468785</td>\n",
       "      <td>0.024141</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.766322</td>\n",
       "      <td>0.098413</td>\n",
       "      <td>0.009604</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.0125, 'max_depth': 2, 'n_e...</td>\n",
       "      <td>0.536822</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565891</td>\n",
       "      <td>0.563953</td>\n",
       "      <td>0.529070</td>\n",
       "      <td>0.567829</td>\n",
       "      <td>0.594961</td>\n",
       "      <td>0.532039</td>\n",
       "      <td>0.557282</td>\n",
       "      <td>0.563587</td>\n",
       "      <td>0.028934</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.187579</td>\n",
       "      <td>0.206016</td>\n",
       "      <td>0.011247</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.0125, 'max_depth': 2, 'n_e...</td>\n",
       "      <td>0.585271</td>\n",
       "      <td>0.610465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600775</td>\n",
       "      <td>0.602713</td>\n",
       "      <td>0.562016</td>\n",
       "      <td>0.600775</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.563107</td>\n",
       "      <td>0.588350</td>\n",
       "      <td>0.596545</td>\n",
       "      <td>0.023266</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.874953</td>\n",
       "      <td>0.195852</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "      <td>{'learning_rate': 0.0125, 'max_depth': 2, 'n_e...</td>\n",
       "      <td>0.606589</td>\n",
       "      <td>0.620155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606589</td>\n",
       "      <td>0.625969</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.622093</td>\n",
       "      <td>0.622093</td>\n",
       "      <td>0.598058</td>\n",
       "      <td>0.619417</td>\n",
       "      <td>0.616710</td>\n",
       "      <td>0.019884</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.791862</td>\n",
       "      <td>0.269761</td>\n",
       "      <td>0.016679</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.0125, 'max_depth': 2, 'n_e...</td>\n",
       "      <td>0.616279</td>\n",
       "      <td>0.641473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.624031</td>\n",
       "      <td>0.647287</td>\n",
       "      <td>0.594961</td>\n",
       "      <td>0.641473</td>\n",
       "      <td>0.624031</td>\n",
       "      <td>0.615534</td>\n",
       "      <td>0.623301</td>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.019869</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.652195</td>\n",
       "      <td>0.210139</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.0125, 'max_depth': 3, 'n_e...</td>\n",
       "      <td>0.492248</td>\n",
       "      <td>0.523256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527132</td>\n",
       "      <td>0.519380</td>\n",
       "      <td>0.478682</td>\n",
       "      <td>0.523256</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.508738</td>\n",
       "      <td>0.500971</td>\n",
       "      <td>0.518804</td>\n",
       "      <td>0.026042</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20.577216</td>\n",
       "      <td>0.300280</td>\n",
       "      <td>0.011015</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.0125, 'max_depth': 3, 'n_e...</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.616279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.600775</td>\n",
       "      <td>0.565891</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.624031</td>\n",
       "      <td>0.576699</td>\n",
       "      <td>0.588350</td>\n",
       "      <td>0.601780</td>\n",
       "      <td>0.024643</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30.450071</td>\n",
       "      <td>0.270080</td>\n",
       "      <td>0.014974</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.0125, 'max_depth': 3, 'n_e...</td>\n",
       "      <td>0.606589</td>\n",
       "      <td>0.639535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.643411</td>\n",
       "      <td>0.598837</td>\n",
       "      <td>0.637597</td>\n",
       "      <td>0.625969</td>\n",
       "      <td>0.605825</td>\n",
       "      <td>0.613592</td>\n",
       "      <td>0.626015</td>\n",
       "      <td>0.018748</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39.585106</td>\n",
       "      <td>0.528081</td>\n",
       "      <td>0.018054</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>{'learning_rate': 0.0125, 'max_depth': 3, 'n_e...</td>\n",
       "      <td>0.625969</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639535</td>\n",
       "      <td>0.649225</td>\n",
       "      <td>0.606589</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.643411</td>\n",
       "      <td>0.629126</td>\n",
       "      <td>0.640777</td>\n",
       "      <td>0.641914</td>\n",
       "      <td>0.017776</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50.057686</td>\n",
       "      <td>1.104597</td>\n",
       "      <td>0.021111</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.0125, 'max_depth': 3, 'n_e...</td>\n",
       "      <td>0.637597</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647287</td>\n",
       "      <td>0.653101</td>\n",
       "      <td>0.614341</td>\n",
       "      <td>0.660853</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.644660</td>\n",
       "      <td>0.642718</td>\n",
       "      <td>0.649863</td>\n",
       "      <td>0.016568</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13.228981</td>\n",
       "      <td>0.316810</td>\n",
       "      <td>0.008518</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.0125, 'max_depth': 4, 'n_e...</td>\n",
       "      <td>0.529070</td>\n",
       "      <td>0.569767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563953</td>\n",
       "      <td>0.546512</td>\n",
       "      <td>0.544574</td>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.566990</td>\n",
       "      <td>0.533981</td>\n",
       "      <td>0.562620</td>\n",
       "      <td>0.024406</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25.916348</td>\n",
       "      <td>0.130994</td>\n",
       "      <td>0.013314</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.0125, 'max_depth': 4, 'n_e...</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.649225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.631783</td>\n",
       "      <td>0.618217</td>\n",
       "      <td>0.610465</td>\n",
       "      <td>0.639535</td>\n",
       "      <td>0.631783</td>\n",
       "      <td>0.609709</td>\n",
       "      <td>0.609709</td>\n",
       "      <td>0.628535</td>\n",
       "      <td>0.022261</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>39.116209</td>\n",
       "      <td>0.220882</td>\n",
       "      <td>0.017076</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.0125, 'max_depth': 4, 'n_e...</td>\n",
       "      <td>0.629845</td>\n",
       "      <td>0.664729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.641473</td>\n",
       "      <td>0.645349</td>\n",
       "      <td>0.625969</td>\n",
       "      <td>0.656977</td>\n",
       "      <td>0.653101</td>\n",
       "      <td>0.638835</td>\n",
       "      <td>0.642718</td>\n",
       "      <td>0.648700</td>\n",
       "      <td>0.017197</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>51.775956</td>\n",
       "      <td>0.361831</td>\n",
       "      <td>0.021310</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>{'learning_rate': 0.0125, 'max_depth': 4, 'n_e...</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.649225</td>\n",
       "      <td>0.664729</td>\n",
       "      <td>0.641473</td>\n",
       "      <td>0.676357</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>0.652427</td>\n",
       "      <td>0.642718</td>\n",
       "      <td>0.660138</td>\n",
       "      <td>0.015125</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>63.882233</td>\n",
       "      <td>0.298826</td>\n",
       "      <td>0.025053</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.0125, 'max_depth': 4, 'n_e...</td>\n",
       "      <td>0.660853</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.653101</td>\n",
       "      <td>0.670543</td>\n",
       "      <td>0.645349</td>\n",
       "      <td>0.682171</td>\n",
       "      <td>0.660853</td>\n",
       "      <td>0.660194</td>\n",
       "      <td>0.644660</td>\n",
       "      <td>0.665179</td>\n",
       "      <td>0.015150</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.735024</td>\n",
       "      <td>0.239150</td>\n",
       "      <td>0.009594</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.0125, 'max_depth': 5, 'n_e...</td>\n",
       "      <td>0.552326</td>\n",
       "      <td>0.594961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593023</td>\n",
       "      <td>0.569767</td>\n",
       "      <td>0.567829</td>\n",
       "      <td>0.593023</td>\n",
       "      <td>0.600775</td>\n",
       "      <td>0.584466</td>\n",
       "      <td>0.563107</td>\n",
       "      <td>0.585885</td>\n",
       "      <td>0.023490</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>32.567036</td>\n",
       "      <td>0.335669</td>\n",
       "      <td>0.015199</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.0125, 'max_depth': 5, 'n_e...</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.641473</td>\n",
       "      <td>0.645349</td>\n",
       "      <td>0.616279</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.643411</td>\n",
       "      <td>0.633010</td>\n",
       "      <td>0.625243</td>\n",
       "      <td>0.643852</td>\n",
       "      <td>0.020021</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>48.500060</td>\n",
       "      <td>0.765309</td>\n",
       "      <td>0.021060</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.0125, 'max_depth': 5, 'n_e...</td>\n",
       "      <td>0.653101</td>\n",
       "      <td>0.676357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.656977</td>\n",
       "      <td>0.660853</td>\n",
       "      <td>0.629845</td>\n",
       "      <td>0.680233</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>0.654369</td>\n",
       "      <td>0.656311</td>\n",
       "      <td>0.662465</td>\n",
       "      <td>0.017463</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>67.438475</td>\n",
       "      <td>0.632584</td>\n",
       "      <td>0.027278</td>\n",
       "      <td>0.003411</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>5</td>\n",
       "      <td>400</td>\n",
       "      <td>{'learning_rate': 0.0125, 'max_depth': 5, 'n_e...</td>\n",
       "      <td>0.660853</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664729</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>0.641473</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>0.662791</td>\n",
       "      <td>0.666019</td>\n",
       "      <td>0.656311</td>\n",
       "      <td>0.668088</td>\n",
       "      <td>0.015962</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>88.825641</td>\n",
       "      <td>2.529627</td>\n",
       "      <td>0.031923</td>\n",
       "      <td>0.004851</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.0125, 'max_depth': 5, 'n_e...</td>\n",
       "      <td>0.662791</td>\n",
       "      <td>0.682171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668605</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>0.643411</td>\n",
       "      <td>0.695736</td>\n",
       "      <td>0.672481</td>\n",
       "      <td>0.664078</td>\n",
       "      <td>0.667961</td>\n",
       "      <td>0.672159</td>\n",
       "      <td>0.017172</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6.026734</td>\n",
       "      <td>0.298470</td>\n",
       "      <td>0.005877</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.025</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.025, 'max_depth': 2, 'n_es...</td>\n",
       "      <td>0.536822</td>\n",
       "      <td>0.569767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562016</td>\n",
       "      <td>0.560078</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.571705</td>\n",
       "      <td>0.591085</td>\n",
       "      <td>0.532039</td>\n",
       "      <td>0.557282</td>\n",
       "      <td>0.564362</td>\n",
       "      <td>0.027536</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13.094566</td>\n",
       "      <td>0.144679</td>\n",
       "      <td>0.008739</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.025</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.025, 'max_depth': 2, 'n_es...</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.616279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.616279</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.624031</td>\n",
       "      <td>0.622093</td>\n",
       "      <td>0.592233</td>\n",
       "      <td>0.617476</td>\n",
       "      <td>0.616128</td>\n",
       "      <td>0.019199</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20.498622</td>\n",
       "      <td>0.457327</td>\n",
       "      <td>0.012472</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.025</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.025, 'max_depth': 2, 'n_es...</td>\n",
       "      <td>0.629845</td>\n",
       "      <td>0.656977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625969</td>\n",
       "      <td>0.649225</td>\n",
       "      <td>0.600775</td>\n",
       "      <td>0.655039</td>\n",
       "      <td>0.633721</td>\n",
       "      <td>0.621359</td>\n",
       "      <td>0.636893</td>\n",
       "      <td>0.638424</td>\n",
       "      <td>0.019988</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>27.121947</td>\n",
       "      <td>0.290060</td>\n",
       "      <td>0.014746</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>0.025</td>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "      <td>{'learning_rate': 0.025, 'max_depth': 2, 'n_es...</td>\n",
       "      <td>0.631783</td>\n",
       "      <td>0.670543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.635659</td>\n",
       "      <td>0.672481</td>\n",
       "      <td>0.614341</td>\n",
       "      <td>0.662791</td>\n",
       "      <td>0.647287</td>\n",
       "      <td>0.627184</td>\n",
       "      <td>0.640777</td>\n",
       "      <td>0.647729</td>\n",
       "      <td>0.020145</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>34.442225</td>\n",
       "      <td>0.833344</td>\n",
       "      <td>0.017840</td>\n",
       "      <td>0.005317</td>\n",
       "      <td>0.025</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.025, 'max_depth': 2, 'n_es...</td>\n",
       "      <td>0.649225</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643411</td>\n",
       "      <td>0.670543</td>\n",
       "      <td>0.618217</td>\n",
       "      <td>0.664729</td>\n",
       "      <td>0.653101</td>\n",
       "      <td>0.640777</td>\n",
       "      <td>0.652427</td>\n",
       "      <td>0.653546</td>\n",
       "      <td>0.016251</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10.761776</td>\n",
       "      <td>0.730997</td>\n",
       "      <td>0.007548</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.025</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.025, 'max_depth': 3, 'n_es...</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.620155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614341</td>\n",
       "      <td>0.610465</td>\n",
       "      <td>0.567829</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.622093</td>\n",
       "      <td>0.584466</td>\n",
       "      <td>0.584466</td>\n",
       "      <td>0.604495</td>\n",
       "      <td>0.023759</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20.407265</td>\n",
       "      <td>0.303444</td>\n",
       "      <td>0.010984</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>0.025</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.025, 'max_depth': 3, 'n_es...</td>\n",
       "      <td>0.622093</td>\n",
       "      <td>0.664729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639535</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.612403</td>\n",
       "      <td>0.653101</td>\n",
       "      <td>0.643411</td>\n",
       "      <td>0.625243</td>\n",
       "      <td>0.642718</td>\n",
       "      <td>0.642495</td>\n",
       "      <td>0.017602</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>32.486951</td>\n",
       "      <td>0.643348</td>\n",
       "      <td>0.016299</td>\n",
       "      <td>0.003182</td>\n",
       "      <td>0.025</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.025, 'max_depth': 3, 'n_es...</td>\n",
       "      <td>0.643411</td>\n",
       "      <td>0.682171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.662791</td>\n",
       "      <td>0.620155</td>\n",
       "      <td>0.662791</td>\n",
       "      <td>0.656977</td>\n",
       "      <td>0.658252</td>\n",
       "      <td>0.648544</td>\n",
       "      <td>0.656844</td>\n",
       "      <td>0.017274</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>40.252399</td>\n",
       "      <td>0.642391</td>\n",
       "      <td>0.016720</td>\n",
       "      <td>0.001809</td>\n",
       "      <td>0.025</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>{'learning_rate': 0.025, 'max_depth': 3, 'n_es...</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>0.687984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.656977</td>\n",
       "      <td>0.664729</td>\n",
       "      <td>0.624031</td>\n",
       "      <td>0.660853</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>0.652427</td>\n",
       "      <td>0.656311</td>\n",
       "      <td>0.660139</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>50.509564</td>\n",
       "      <td>0.417275</td>\n",
       "      <td>0.020035</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.025</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.025, 'max_depth': 3, 'n_es...</td>\n",
       "      <td>0.672481</td>\n",
       "      <td>0.691860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>0.662791</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.662791</td>\n",
       "      <td>0.652427</td>\n",
       "      <td>0.664078</td>\n",
       "      <td>0.664403</td>\n",
       "      <td>0.016504</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>13.788152</td>\n",
       "      <td>0.138299</td>\n",
       "      <td>0.008102</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.655039</td>\n",
       "      <td>0.668605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645349</td>\n",
       "      <td>0.672481</td>\n",
       "      <td>0.633721</td>\n",
       "      <td>0.676357</td>\n",
       "      <td>0.660853</td>\n",
       "      <td>0.660194</td>\n",
       "      <td>0.646602</td>\n",
       "      <td>0.661108</td>\n",
       "      <td>0.016157</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>26.178447</td>\n",
       "      <td>0.161428</td>\n",
       "      <td>0.012657</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.672481</td>\n",
       "      <td>0.682171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.676357</td>\n",
       "      <td>0.643411</td>\n",
       "      <td>0.684109</td>\n",
       "      <td>0.672481</td>\n",
       "      <td>0.658252</td>\n",
       "      <td>0.654369</td>\n",
       "      <td>0.669637</td>\n",
       "      <td>0.013253</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>38.863071</td>\n",
       "      <td>0.131509</td>\n",
       "      <td>0.015014</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.672481</td>\n",
       "      <td>0.668605</td>\n",
       "      <td>0.643411</td>\n",
       "      <td>0.687984</td>\n",
       "      <td>0.678295</td>\n",
       "      <td>0.671845</td>\n",
       "      <td>0.662136</td>\n",
       "      <td>0.672547</td>\n",
       "      <td>0.012205</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>52.946771</td>\n",
       "      <td>0.433384</td>\n",
       "      <td>0.017896</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.670543</td>\n",
       "      <td>0.693798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670543</td>\n",
       "      <td>0.662791</td>\n",
       "      <td>0.629845</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>0.680233</td>\n",
       "      <td>0.677670</td>\n",
       "      <td>0.669903</td>\n",
       "      <td>0.672742</td>\n",
       "      <td>0.016838</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>66.441089</td>\n",
       "      <td>0.799794</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.664729</td>\n",
       "      <td>0.691860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664729</td>\n",
       "      <td>0.672481</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.684109</td>\n",
       "      <td>0.682171</td>\n",
       "      <td>0.677670</td>\n",
       "      <td>0.656311</td>\n",
       "      <td>0.670803</td>\n",
       "      <td>0.017766</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>17.410692</td>\n",
       "      <td>0.435979</td>\n",
       "      <td>0.008901</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.678295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668605</td>\n",
       "      <td>0.672481</td>\n",
       "      <td>0.645349</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.673786</td>\n",
       "      <td>0.666019</td>\n",
       "      <td>0.672160</td>\n",
       "      <td>0.013092</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>33.843916</td>\n",
       "      <td>0.246150</td>\n",
       "      <td>0.013436</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.678295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680233</td>\n",
       "      <td>0.660853</td>\n",
       "      <td>0.653101</td>\n",
       "      <td>0.687984</td>\n",
       "      <td>0.670543</td>\n",
       "      <td>0.671845</td>\n",
       "      <td>0.679612</td>\n",
       "      <td>0.674874</td>\n",
       "      <td>0.011056</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>50.619012</td>\n",
       "      <td>0.627403</td>\n",
       "      <td>0.017496</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.668605</td>\n",
       "      <td>0.680233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664729</td>\n",
       "      <td>0.660853</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>0.676357</td>\n",
       "      <td>0.679612</td>\n",
       "      <td>0.677670</td>\n",
       "      <td>0.672936</td>\n",
       "      <td>0.010654</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>67.942541</td>\n",
       "      <td>1.402838</td>\n",
       "      <td>0.021945</td>\n",
       "      <td>0.003473</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>400</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.678295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.653101</td>\n",
       "      <td>0.647287</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.685437</td>\n",
       "      <td>0.673786</td>\n",
       "      <td>0.672355</td>\n",
       "      <td>0.012547</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>88.883548</td>\n",
       "      <td>0.795355</td>\n",
       "      <td>0.026029</td>\n",
       "      <td>0.002478</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.678295</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662791</td>\n",
       "      <td>0.668605</td>\n",
       "      <td>0.643411</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.677670</td>\n",
       "      <td>0.675728</td>\n",
       "      <td>0.670997</td>\n",
       "      <td>0.011136</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>6.593016</td>\n",
       "      <td>0.206879</td>\n",
       "      <td>0.006487</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.643411</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633721</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.614341</td>\n",
       "      <td>0.662791</td>\n",
       "      <td>0.645349</td>\n",
       "      <td>0.627184</td>\n",
       "      <td>0.642718</td>\n",
       "      <td>0.649280</td>\n",
       "      <td>0.020599</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>13.246373</td>\n",
       "      <td>0.140737</td>\n",
       "      <td>0.008060</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.670543</td>\n",
       "      <td>0.678295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.668605</td>\n",
       "      <td>0.635659</td>\n",
       "      <td>0.664729</td>\n",
       "      <td>0.662791</td>\n",
       "      <td>0.644660</td>\n",
       "      <td>0.660194</td>\n",
       "      <td>0.662076</td>\n",
       "      <td>0.014122</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>20.491575</td>\n",
       "      <td>0.380619</td>\n",
       "      <td>0.010028</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.670543</td>\n",
       "      <td>0.678295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643411</td>\n",
       "      <td>0.672481</td>\n",
       "      <td>0.647287</td>\n",
       "      <td>0.672481</td>\n",
       "      <td>0.670543</td>\n",
       "      <td>0.654369</td>\n",
       "      <td>0.669903</td>\n",
       "      <td>0.665955</td>\n",
       "      <td>0.012207</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>26.274706</td>\n",
       "      <td>0.307104</td>\n",
       "      <td>0.012886</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.670543</td>\n",
       "      <td>0.676357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.656977</td>\n",
       "      <td>0.664729</td>\n",
       "      <td>0.653101</td>\n",
       "      <td>0.672481</td>\n",
       "      <td>0.670543</td>\n",
       "      <td>0.656311</td>\n",
       "      <td>0.667961</td>\n",
       "      <td>0.666730</td>\n",
       "      <td>0.008268</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>33.224415</td>\n",
       "      <td>0.319884</td>\n",
       "      <td>0.016516</td>\n",
       "      <td>0.008817</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.668605</td>\n",
       "      <td>0.682171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655039</td>\n",
       "      <td>0.664729</td>\n",
       "      <td>0.643411</td>\n",
       "      <td>0.668605</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.654369</td>\n",
       "      <td>0.673786</td>\n",
       "      <td>0.666536</td>\n",
       "      <td>0.011720</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>10.193479</td>\n",
       "      <td>0.096159</td>\n",
       "      <td>0.006794</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.662791</td>\n",
       "      <td>0.676357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645349</td>\n",
       "      <td>0.656977</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.656977</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.654369</td>\n",
       "      <td>0.656311</td>\n",
       "      <td>0.658976</td>\n",
       "      <td>0.015154</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>20.095144</td>\n",
       "      <td>0.126562</td>\n",
       "      <td>0.010607</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.672481</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.639535</td>\n",
       "      <td>0.672481</td>\n",
       "      <td>0.670543</td>\n",
       "      <td>0.650485</td>\n",
       "      <td>0.658252</td>\n",
       "      <td>0.667504</td>\n",
       "      <td>0.013727</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>29.629172</td>\n",
       "      <td>0.962447</td>\n",
       "      <td>0.011032</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.672481</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.668605</td>\n",
       "      <td>0.653101</td>\n",
       "      <td>0.670543</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.642718</td>\n",
       "      <td>0.667961</td>\n",
       "      <td>0.668667</td>\n",
       "      <td>0.011668</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>38.622640</td>\n",
       "      <td>0.899360</td>\n",
       "      <td>0.014734</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.680233</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.643411</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.672481</td>\n",
       "      <td>0.644660</td>\n",
       "      <td>0.673786</td>\n",
       "      <td>0.669249</td>\n",
       "      <td>0.013478</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>49.161739</td>\n",
       "      <td>0.566276</td>\n",
       "      <td>0.016308</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.672481</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668605</td>\n",
       "      <td>0.664729</td>\n",
       "      <td>0.639535</td>\n",
       "      <td>0.672481</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.644660</td>\n",
       "      <td>0.685437</td>\n",
       "      <td>0.668668</td>\n",
       "      <td>0.014759</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>13.413146</td>\n",
       "      <td>0.269935</td>\n",
       "      <td>0.007885</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 4, 'n_esti...</td>\n",
       "      <td>0.660853</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668605</td>\n",
       "      <td>0.662791</td>\n",
       "      <td>0.635659</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>0.678295</td>\n",
       "      <td>0.662136</td>\n",
       "      <td>0.658252</td>\n",
       "      <td>0.667118</td>\n",
       "      <td>0.014067</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>25.975723</td>\n",
       "      <td>0.086436</td>\n",
       "      <td>0.010775</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 4, 'n_esti...</td>\n",
       "      <td>0.662791</td>\n",
       "      <td>0.678295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.676357</td>\n",
       "      <td>0.643411</td>\n",
       "      <td>0.645349</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>0.670543</td>\n",
       "      <td>0.660194</td>\n",
       "      <td>0.658252</td>\n",
       "      <td>0.665567</td>\n",
       "      <td>0.013383</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>39.257790</td>\n",
       "      <td>0.629596</td>\n",
       "      <td>0.014212</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 4, 'n_esti...</td>\n",
       "      <td>0.660853</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.660853</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.682171</td>\n",
       "      <td>0.660853</td>\n",
       "      <td>0.667961</td>\n",
       "      <td>0.662136</td>\n",
       "      <td>0.665762</td>\n",
       "      <td>0.015344</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>53.500417</td>\n",
       "      <td>0.471433</td>\n",
       "      <td>0.017186</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 4, 'n_esti...</td>\n",
       "      <td>0.676357</td>\n",
       "      <td>0.689922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.672481</td>\n",
       "      <td>0.653101</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.699612</td>\n",
       "      <td>0.668605</td>\n",
       "      <td>0.660194</td>\n",
       "      <td>0.666019</td>\n",
       "      <td>0.668475</td>\n",
       "      <td>0.018626</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>63.760911</td>\n",
       "      <td>0.832339</td>\n",
       "      <td>0.019196</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 4, 'n_esti...</td>\n",
       "      <td>0.664729</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670543</td>\n",
       "      <td>0.668605</td>\n",
       "      <td>0.633721</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>0.662791</td>\n",
       "      <td>0.658252</td>\n",
       "      <td>0.679612</td>\n",
       "      <td>0.667700</td>\n",
       "      <td>0.014498</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>16.679091</td>\n",
       "      <td>0.234168</td>\n",
       "      <td>0.008253</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.672481</td>\n",
       "      <td>0.676357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.656977</td>\n",
       "      <td>0.643411</td>\n",
       "      <td>0.707364</td>\n",
       "      <td>0.670543</td>\n",
       "      <td>0.660194</td>\n",
       "      <td>0.667961</td>\n",
       "      <td>0.671577</td>\n",
       "      <td>0.016348</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>32.893647</td>\n",
       "      <td>0.262447</td>\n",
       "      <td>0.012299</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.668605</td>\n",
       "      <td>0.684109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682171</td>\n",
       "      <td>0.670543</td>\n",
       "      <td>0.643411</td>\n",
       "      <td>0.699612</td>\n",
       "      <td>0.664729</td>\n",
       "      <td>0.669903</td>\n",
       "      <td>0.671845</td>\n",
       "      <td>0.673516</td>\n",
       "      <td>0.013950</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>48.950847</td>\n",
       "      <td>0.260185</td>\n",
       "      <td>0.016243</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.678295</td>\n",
       "      <td>0.678295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.662791</td>\n",
       "      <td>0.637597</td>\n",
       "      <td>0.684109</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.669903</td>\n",
       "      <td>0.685437</td>\n",
       "      <td>0.670997</td>\n",
       "      <td>0.013053</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>66.066258</td>\n",
       "      <td>0.488433</td>\n",
       "      <td>0.019858</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>400</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.660853</td>\n",
       "      <td>0.670543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668605</td>\n",
       "      <td>0.653101</td>\n",
       "      <td>0.641473</td>\n",
       "      <td>0.695736</td>\n",
       "      <td>0.668605</td>\n",
       "      <td>0.673786</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.667508</td>\n",
       "      <td>0.014210</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>72.926388</td>\n",
       "      <td>10.116045</td>\n",
       "      <td>0.020096</td>\n",
       "      <td>0.004705</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.662791</td>\n",
       "      <td>0.662791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664729</td>\n",
       "      <td>0.664729</td>\n",
       "      <td>0.639535</td>\n",
       "      <td>0.687984</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>0.658252</td>\n",
       "      <td>0.673786</td>\n",
       "      <td>0.664404</td>\n",
       "      <td>0.011721</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        7.153762      0.122710         0.007125        0.000652   \n",
       "1       13.766322      0.098413         0.009604        0.000704   \n",
       "2       20.187579      0.206016         0.011247        0.000186   \n",
       "3       26.874953      0.195852         0.014151        0.000975   \n",
       "4       33.791862      0.269761         0.016679        0.001321   \n",
       "5       10.652195      0.210139         0.007849        0.000649   \n",
       "6       20.577216      0.300280         0.011015        0.000279   \n",
       "7       30.450071      0.270080         0.014974        0.002256   \n",
       "8       39.585106      0.528081         0.018054        0.000718   \n",
       "9       50.057686      1.104597         0.021111        0.000821   \n",
       "10      13.228981      0.316810         0.008518        0.000227   \n",
       "11      25.916348      0.130994         0.013314        0.000864   \n",
       "12      39.116209      0.220882         0.017076        0.000451   \n",
       "13      51.775956      0.361831         0.021310        0.000376   \n",
       "14      63.882233      0.298826         0.025053        0.000585   \n",
       "15      16.735024      0.239150         0.009594        0.000311   \n",
       "16      32.567036      0.335669         0.015199        0.000393   \n",
       "17      48.500060      0.765309         0.021060        0.001165   \n",
       "18      67.438475      0.632584         0.027278        0.003411   \n",
       "19      88.825641      2.529627         0.031923        0.004851   \n",
       "20       6.026734      0.298470         0.005877        0.000416   \n",
       "21      13.094566      0.144679         0.008739        0.000429   \n",
       "22      20.498622      0.457327         0.012472        0.001704   \n",
       "23      27.121947      0.290060         0.014746        0.001457   \n",
       "24      34.442225      0.833344         0.017840        0.005317   \n",
       "25      10.761776      0.730997         0.007548        0.000429   \n",
       "26      20.407265      0.303444         0.010984        0.001012   \n",
       "27      32.486951      0.643348         0.016299        0.003182   \n",
       "28      40.252399      0.642391         0.016720        0.001809   \n",
       "29      50.509564      0.417275         0.020035        0.002600   \n",
       "..            ...           ...              ...             ...   \n",
       "50      13.788152      0.138299         0.008102        0.000532   \n",
       "51      26.178447      0.161428         0.012657        0.001287   \n",
       "52      38.863071      0.131509         0.015014        0.000755   \n",
       "53      52.946771      0.433384         0.017896        0.000913   \n",
       "54      66.441089      0.799794         0.020619        0.001115   \n",
       "55      17.410692      0.435979         0.008901        0.000249   \n",
       "56      33.843916      0.246150         0.013436        0.001001   \n",
       "57      50.619012      0.627403         0.017496        0.000527   \n",
       "58      67.942541      1.402838         0.021945        0.003473   \n",
       "59      88.883548      0.795355         0.026029        0.002478   \n",
       "60       6.593016      0.206879         0.006487        0.000554   \n",
       "61      13.246373      0.140737         0.008060        0.000216   \n",
       "62      20.491575      0.380619         0.010028        0.000132   \n",
       "63      26.274706      0.307104         0.012886        0.002419   \n",
       "64      33.224415      0.319884         0.016516        0.008817   \n",
       "65      10.193479      0.096159         0.006794        0.000212   \n",
       "66      20.095144      0.126562         0.010607        0.001497   \n",
       "67      29.629172      0.962447         0.011032        0.001015   \n",
       "68      38.622640      0.899360         0.014734        0.002184   \n",
       "69      49.161739      0.566276         0.016308        0.000277   \n",
       "70      13.413146      0.269935         0.007885        0.000665   \n",
       "71      25.975723      0.086436         0.010775        0.000392   \n",
       "72      39.257790      0.629596         0.014212        0.001068   \n",
       "73      53.500417      0.471433         0.017186        0.001178   \n",
       "74      63.760911      0.832339         0.019196        0.000606   \n",
       "75      16.679091      0.234168         0.008253        0.000224   \n",
       "76      32.893647      0.262447         0.012299        0.000540   \n",
       "77      48.950847      0.260185         0.016243        0.000631   \n",
       "78      66.066258      0.488433         0.019858        0.000619   \n",
       "79      72.926388     10.116045         0.020096        0.004705   \n",
       "\n",
       "   param_learning_rate param_max_depth param_n_estimators  \\\n",
       "0               0.0125               2                100   \n",
       "1               0.0125               2                200   \n",
       "2               0.0125               2                300   \n",
       "3               0.0125               2                400   \n",
       "4               0.0125               2                500   \n",
       "5               0.0125               3                100   \n",
       "6               0.0125               3                200   \n",
       "7               0.0125               3                300   \n",
       "8               0.0125               3                400   \n",
       "9               0.0125               3                500   \n",
       "10              0.0125               4                100   \n",
       "11              0.0125               4                200   \n",
       "12              0.0125               4                300   \n",
       "13              0.0125               4                400   \n",
       "14              0.0125               4                500   \n",
       "15              0.0125               5                100   \n",
       "16              0.0125               5                200   \n",
       "17              0.0125               5                300   \n",
       "18              0.0125               5                400   \n",
       "19              0.0125               5                500   \n",
       "20               0.025               2                100   \n",
       "21               0.025               2                200   \n",
       "22               0.025               2                300   \n",
       "23               0.025               2                400   \n",
       "24               0.025               2                500   \n",
       "25               0.025               3                100   \n",
       "26               0.025               3                200   \n",
       "27               0.025               3                300   \n",
       "28               0.025               3                400   \n",
       "29               0.025               3                500   \n",
       "..                 ...             ...                ...   \n",
       "50                0.05               4                100   \n",
       "51                0.05               4                200   \n",
       "52                0.05               4                300   \n",
       "53                0.05               4                400   \n",
       "54                0.05               4                500   \n",
       "55                0.05               5                100   \n",
       "56                0.05               5                200   \n",
       "57                0.05               5                300   \n",
       "58                0.05               5                400   \n",
       "59                0.05               5                500   \n",
       "60                 0.1               2                100   \n",
       "61                 0.1               2                200   \n",
       "62                 0.1               2                300   \n",
       "63                 0.1               2                400   \n",
       "64                 0.1               2                500   \n",
       "65                 0.1               3                100   \n",
       "66                 0.1               3                200   \n",
       "67                 0.1               3                300   \n",
       "68                 0.1               3                400   \n",
       "69                 0.1               3                500   \n",
       "70                 0.1               4                100   \n",
       "71                 0.1               4                200   \n",
       "72                 0.1               4                300   \n",
       "73                 0.1               4                400   \n",
       "74                 0.1               4                500   \n",
       "75                 0.1               5                100   \n",
       "76                 0.1               5                200   \n",
       "77                 0.1               5                300   \n",
       "78                 0.1               5                400   \n",
       "79                 0.1               5                500   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'learning_rate': 0.0125, 'max_depth': 2, 'n_e...           0.426357   \n",
       "1   {'learning_rate': 0.0125, 'max_depth': 2, 'n_e...           0.536822   \n",
       "2   {'learning_rate': 0.0125, 'max_depth': 2, 'n_e...           0.585271   \n",
       "3   {'learning_rate': 0.0125, 'max_depth': 2, 'n_e...           0.606589   \n",
       "4   {'learning_rate': 0.0125, 'max_depth': 2, 'n_e...           0.616279   \n",
       "5   {'learning_rate': 0.0125, 'max_depth': 3, 'n_e...           0.492248   \n",
       "6   {'learning_rate': 0.0125, 'max_depth': 3, 'n_e...           0.581395   \n",
       "7   {'learning_rate': 0.0125, 'max_depth': 3, 'n_e...           0.606589   \n",
       "8   {'learning_rate': 0.0125, 'max_depth': 3, 'n_e...           0.625969   \n",
       "9   {'learning_rate': 0.0125, 'max_depth': 3, 'n_e...           0.637597   \n",
       "10  {'learning_rate': 0.0125, 'max_depth': 4, 'n_e...           0.529070   \n",
       "11  {'learning_rate': 0.0125, 'max_depth': 4, 'n_e...           0.604651   \n",
       "12  {'learning_rate': 0.0125, 'max_depth': 4, 'n_e...           0.629845   \n",
       "13  {'learning_rate': 0.0125, 'max_depth': 4, 'n_e...           0.651163   \n",
       "14  {'learning_rate': 0.0125, 'max_depth': 4, 'n_e...           0.660853   \n",
       "15  {'learning_rate': 0.0125, 'max_depth': 5, 'n_e...           0.552326   \n",
       "16  {'learning_rate': 0.0125, 'max_depth': 5, 'n_e...           0.627907   \n",
       "17  {'learning_rate': 0.0125, 'max_depth': 5, 'n_e...           0.653101   \n",
       "18  {'learning_rate': 0.0125, 'max_depth': 5, 'n_e...           0.660853   \n",
       "19  {'learning_rate': 0.0125, 'max_depth': 5, 'n_e...           0.662791   \n",
       "20  {'learning_rate': 0.025, 'max_depth': 2, 'n_es...           0.536822   \n",
       "21  {'learning_rate': 0.025, 'max_depth': 2, 'n_es...           0.604651   \n",
       "22  {'learning_rate': 0.025, 'max_depth': 2, 'n_es...           0.629845   \n",
       "23  {'learning_rate': 0.025, 'max_depth': 2, 'n_es...           0.631783   \n",
       "24  {'learning_rate': 0.025, 'max_depth': 2, 'n_es...           0.649225   \n",
       "25  {'learning_rate': 0.025, 'max_depth': 3, 'n_es...           0.583333   \n",
       "26  {'learning_rate': 0.025, 'max_depth': 3, 'n_es...           0.622093   \n",
       "27  {'learning_rate': 0.025, 'max_depth': 3, 'n_es...           0.643411   \n",
       "28  {'learning_rate': 0.025, 'max_depth': 3, 'n_es...           0.658915   \n",
       "29  {'learning_rate': 0.025, 'max_depth': 3, 'n_es...           0.672481   \n",
       "..                                                ...                ...   \n",
       "50  {'learning_rate': 0.05, 'max_depth': 4, 'n_est...           0.655039   \n",
       "51  {'learning_rate': 0.05, 'max_depth': 4, 'n_est...           0.672481   \n",
       "52  {'learning_rate': 0.05, 'max_depth': 4, 'n_est...           0.674419   \n",
       "53  {'learning_rate': 0.05, 'max_depth': 4, 'n_est...           0.670543   \n",
       "54  {'learning_rate': 0.05, 'max_depth': 4, 'n_est...           0.664729   \n",
       "55  {'learning_rate': 0.05, 'max_depth': 5, 'n_est...           0.666667   \n",
       "56  {'learning_rate': 0.05, 'max_depth': 5, 'n_est...           0.674419   \n",
       "57  {'learning_rate': 0.05, 'max_depth': 5, 'n_est...           0.668605   \n",
       "58  {'learning_rate': 0.05, 'max_depth': 5, 'n_est...           0.674419   \n",
       "59  {'learning_rate': 0.05, 'max_depth': 5, 'n_est...           0.678295   \n",
       "60  {'learning_rate': 0.1, 'max_depth': 2, 'n_esti...           0.643411   \n",
       "61  {'learning_rate': 0.1, 'max_depth': 2, 'n_esti...           0.670543   \n",
       "62  {'learning_rate': 0.1, 'max_depth': 2, 'n_esti...           0.670543   \n",
       "63  {'learning_rate': 0.1, 'max_depth': 2, 'n_esti...           0.670543   \n",
       "64  {'learning_rate': 0.1, 'max_depth': 2, 'n_esti...           0.668605   \n",
       "65  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.662791   \n",
       "66  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.672481   \n",
       "67  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.672481   \n",
       "68  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.680233   \n",
       "69  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.672481   \n",
       "70  {'learning_rate': 0.1, 'max_depth': 4, 'n_esti...           0.660853   \n",
       "71  {'learning_rate': 0.1, 'max_depth': 4, 'n_esti...           0.662791   \n",
       "72  {'learning_rate': 0.1, 'max_depth': 4, 'n_esti...           0.660853   \n",
       "73  {'learning_rate': 0.1, 'max_depth': 4, 'n_esti...           0.676357   \n",
       "74  {'learning_rate': 0.1, 'max_depth': 4, 'n_esti...           0.664729   \n",
       "75  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.672481   \n",
       "76  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.668605   \n",
       "77  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.678295   \n",
       "78  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.660853   \n",
       "79  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.662791   \n",
       "\n",
       "    split1_test_score  ...  split3_test_score  split4_test_score  \\\n",
       "0            0.461240  ...           0.472868           0.472868   \n",
       "1            0.558140  ...           0.565891           0.563953   \n",
       "2            0.610465  ...           0.600775           0.602713   \n",
       "3            0.620155  ...           0.606589           0.625969   \n",
       "4            0.641473  ...           0.624031           0.647287   \n",
       "5            0.523256  ...           0.527132           0.519380   \n",
       "6            0.616279  ...           0.604651           0.600775   \n",
       "7            0.639535  ...           0.627907           0.643411   \n",
       "8            0.658915  ...           0.639535           0.649225   \n",
       "9            0.674419  ...           0.647287           0.653101   \n",
       "10           0.569767  ...           0.563953           0.546512   \n",
       "11           0.649225  ...           0.631783           0.618217   \n",
       "12           0.664729  ...           0.641473           0.645349   \n",
       "13           0.674419  ...           0.649225           0.664729   \n",
       "14           0.686047  ...           0.653101           0.670543   \n",
       "15           0.594961  ...           0.593023           0.569767   \n",
       "16           0.666667  ...           0.641473           0.645349   \n",
       "17           0.676357  ...           0.656977           0.660853   \n",
       "18           0.686047  ...           0.664729           0.658915   \n",
       "19           0.682171  ...           0.668605           0.658915   \n",
       "20           0.569767  ...           0.562016           0.560078   \n",
       "21           0.616279  ...           0.616279           0.627907   \n",
       "22           0.656977  ...           0.625969           0.649225   \n",
       "23           0.670543  ...           0.635659           0.672481   \n",
       "24           0.666667  ...           0.643411           0.670543   \n",
       "25           0.620155  ...           0.614341           0.610465   \n",
       "26           0.664729  ...           0.639535           0.651163   \n",
       "27           0.682171  ...           0.651163           0.662791   \n",
       "28           0.687984  ...           0.656977           0.664729   \n",
       "29           0.691860  ...           0.658915           0.662791   \n",
       "..                ...  ...                ...                ...   \n",
       "50           0.668605  ...           0.645349           0.672481   \n",
       "51           0.682171  ...           0.666667           0.676357   \n",
       "52           0.686047  ...           0.672481           0.668605   \n",
       "53           0.693798  ...           0.670543           0.662791   \n",
       "54           0.691860  ...           0.664729           0.672481   \n",
       "55           0.678295  ...           0.668605           0.672481   \n",
       "56           0.678295  ...           0.680233           0.660853   \n",
       "57           0.680233  ...           0.664729           0.660853   \n",
       "58           0.678295  ...           0.666667           0.653101   \n",
       "59           0.686047  ...           0.662791           0.668605   \n",
       "60           0.674419  ...           0.633721           0.666667   \n",
       "61           0.678295  ...           0.651163           0.668605   \n",
       "62           0.678295  ...           0.643411           0.672481   \n",
       "63           0.676357  ...           0.656977           0.664729   \n",
       "64           0.682171  ...           0.655039           0.664729   \n",
       "65           0.676357  ...           0.645349           0.656977   \n",
       "66           0.686047  ...           0.666667           0.674419   \n",
       "67           0.686047  ...           0.674419           0.668605   \n",
       "68           0.686047  ...           0.666667           0.674419   \n",
       "69           0.686047  ...           0.668605           0.664729   \n",
       "70           0.674419  ...           0.668605           0.662791   \n",
       "71           0.678295  ...           0.676357           0.643411   \n",
       "72           0.686047  ...           0.674419           0.660853   \n",
       "73           0.689922  ...           0.672481           0.653101   \n",
       "74           0.686047  ...           0.670543           0.668605   \n",
       "75           0.676357  ...           0.674419           0.656977   \n",
       "76           0.684109  ...           0.682171           0.670543   \n",
       "77           0.678295  ...           0.674419           0.662791   \n",
       "78           0.670543  ...           0.668605           0.653101   \n",
       "79           0.662791  ...           0.664729           0.664729   \n",
       "\n",
       "    split5_test_score  split6_test_score  split7_test_score  \\\n",
       "0            0.445736           0.488372           0.486434   \n",
       "1            0.529070           0.567829           0.594961   \n",
       "2            0.562016           0.600775           0.604651   \n",
       "3            0.583333           0.622093           0.622093   \n",
       "4            0.594961           0.641473           0.624031   \n",
       "5            0.478682           0.523256           0.534884   \n",
       "6            0.565891           0.604651           0.624031   \n",
       "7            0.598837           0.637597           0.625969   \n",
       "8            0.606589           0.651163           0.643411   \n",
       "9            0.614341           0.660853           0.651163   \n",
       "10           0.544574           0.573643           0.581395   \n",
       "11           0.610465           0.639535           0.631783   \n",
       "12           0.625969           0.656977           0.653101   \n",
       "13           0.641473           0.676357           0.658915   \n",
       "14           0.645349           0.682171           0.660853   \n",
       "15           0.567829           0.593023           0.600775   \n",
       "16           0.616279           0.651163           0.643411   \n",
       "17           0.629845           0.680233           0.658915   \n",
       "18           0.641473           0.686047           0.662791   \n",
       "19           0.643411           0.695736           0.672481   \n",
       "20           0.534884           0.571705           0.591085   \n",
       "21           0.583333           0.624031           0.622093   \n",
       "22           0.600775           0.655039           0.633721   \n",
       "23           0.614341           0.662791           0.647287   \n",
       "24           0.618217           0.664729           0.653101   \n",
       "25           0.567829           0.604651           0.622093   \n",
       "26           0.612403           0.653101           0.643411   \n",
       "27           0.620155           0.662791           0.656977   \n",
       "28           0.624031           0.660853           0.658915   \n",
       "29           0.627907           0.666667           0.662791   \n",
       "..                ...                ...                ...   \n",
       "50           0.633721           0.676357           0.660853   \n",
       "51           0.643411           0.684109           0.672481   \n",
       "52           0.643411           0.687984           0.678295   \n",
       "53           0.629845           0.686047           0.680233   \n",
       "54           0.627907           0.684109           0.682171   \n",
       "55           0.645349           0.686047           0.666667   \n",
       "56           0.653101           0.687984           0.670543   \n",
       "57           0.651163           0.686047           0.676357   \n",
       "58           0.647287           0.686047           0.674419   \n",
       "59           0.643411           0.674419           0.666667   \n",
       "60           0.614341           0.662791           0.645349   \n",
       "61           0.635659           0.664729           0.662791   \n",
       "62           0.647287           0.672481           0.670543   \n",
       "63           0.653101           0.672481           0.670543   \n",
       "64           0.643411           0.668605           0.674419   \n",
       "65           0.627907           0.656977           0.666667   \n",
       "66           0.639535           0.672481           0.670543   \n",
       "67           0.653101           0.670543           0.674419   \n",
       "68           0.643411           0.674419           0.672481   \n",
       "69           0.639535           0.672481           0.674419   \n",
       "70           0.635659           0.686047           0.678295   \n",
       "71           0.645349           0.686047           0.670543   \n",
       "72           0.627907           0.682171           0.660853   \n",
       "73           0.627907           0.699612           0.668605   \n",
       "74           0.633721           0.686047           0.662791   \n",
       "75           0.643411           0.707364           0.670543   \n",
       "76           0.643411           0.699612           0.664729   \n",
       "77           0.637597           0.684109           0.666667   \n",
       "78           0.641473           0.695736           0.668605   \n",
       "79           0.639535           0.687984           0.658915   \n",
       "\n",
       "    split8_test_score  split9_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.466019           0.450485         0.468785        0.024141   \n",
       "1            0.532039           0.557282         0.563587        0.028934   \n",
       "2            0.563107           0.588350         0.596545        0.023266   \n",
       "3            0.598058           0.619417         0.616710        0.019884   \n",
       "4            0.615534           0.623301         0.629893        0.019869   \n",
       "5            0.508738           0.500971         0.518804        0.026042   \n",
       "6            0.576699           0.588350         0.601780        0.024643   \n",
       "7            0.605825           0.613592         0.626015        0.018748   \n",
       "8            0.629126           0.640777         0.641914        0.017776   \n",
       "9            0.644660           0.642718         0.649863        0.016568   \n",
       "10           0.566990           0.533981         0.562620        0.024406   \n",
       "11           0.609709           0.609709         0.628535        0.022261   \n",
       "12           0.638835           0.642718         0.648700        0.017197   \n",
       "13           0.652427           0.642718         0.660138        0.015125   \n",
       "14           0.660194           0.644660         0.665179        0.015150   \n",
       "15           0.584466           0.563107         0.585885        0.023490   \n",
       "16           0.633010           0.625243         0.643852        0.020021   \n",
       "17           0.654369           0.656311         0.662465        0.017463   \n",
       "18           0.666019           0.656311         0.668088        0.015962   \n",
       "19           0.664078           0.667961         0.672159        0.017172   \n",
       "20           0.532039           0.557282         0.564362        0.027536   \n",
       "21           0.592233           0.617476         0.616128        0.019199   \n",
       "22           0.621359           0.636893         0.638424        0.019988   \n",
       "23           0.627184           0.640777         0.647729        0.020145   \n",
       "24           0.640777           0.652427         0.653546        0.016251   \n",
       "25           0.584466           0.584466         0.604495        0.023759   \n",
       "26           0.625243           0.642718         0.642495        0.017602   \n",
       "27           0.658252           0.648544         0.656844        0.017274   \n",
       "28           0.652427           0.656311         0.660139        0.016100   \n",
       "29           0.652427           0.664078         0.664403        0.016504   \n",
       "..                ...                ...              ...             ...   \n",
       "50           0.660194           0.646602         0.661108        0.016157   \n",
       "51           0.658252           0.654369         0.669637        0.013253   \n",
       "52           0.671845           0.662136         0.672547        0.012205   \n",
       "53           0.677670           0.669903         0.672742        0.016838   \n",
       "54           0.677670           0.656311         0.670803        0.017766   \n",
       "55           0.673786           0.666019         0.672160        0.013092   \n",
       "56           0.671845           0.679612         0.674874        0.011056   \n",
       "57           0.679612           0.677670         0.672936        0.010654   \n",
       "58           0.685437           0.673786         0.672355        0.012547   \n",
       "59           0.677670           0.675728         0.670997        0.011136   \n",
       "60           0.627184           0.642718         0.649280        0.020599   \n",
       "61           0.644660           0.660194         0.662076        0.014122   \n",
       "62           0.654369           0.669903         0.665955        0.012207   \n",
       "63           0.656311           0.667961         0.666730        0.008268   \n",
       "64           0.654369           0.673786         0.666536        0.011720   \n",
       "65           0.654369           0.656311         0.658976        0.015154   \n",
       "66           0.650485           0.658252         0.667504        0.013727   \n",
       "67           0.642718           0.667961         0.668667        0.011668   \n",
       "68           0.644660           0.673786         0.669249        0.013478   \n",
       "69           0.644660           0.685437         0.668668        0.014759   \n",
       "70           0.662136           0.658252         0.667118        0.014067   \n",
       "71           0.660194           0.658252         0.665567        0.013383   \n",
       "72           0.667961           0.662136         0.665762        0.015344   \n",
       "73           0.660194           0.666019         0.668475        0.018626   \n",
       "74           0.658252           0.679612         0.667700        0.014498   \n",
       "75           0.660194           0.667961         0.671577        0.016348   \n",
       "76           0.669903           0.671845         0.673516        0.013950   \n",
       "77           0.669903           0.685437         0.670997        0.013053   \n",
       "78           0.673786           0.681553         0.667508        0.014210   \n",
       "79           0.658252           0.673786         0.664404        0.011721   \n",
       "\n",
       "    rank_test_score  \n",
       "0                80  \n",
       "1                77  \n",
       "2                74  \n",
       "3                69  \n",
       "4                66  \n",
       "5                79  \n",
       "6                73  \n",
       "7                68  \n",
       "8                63  \n",
       "9                54  \n",
       "10               78  \n",
       "11               67  \n",
       "12               56  \n",
       "13               48  \n",
       "14               38  \n",
       "15               75  \n",
       "16               61  \n",
       "17               42  \n",
       "18               26  \n",
       "19               11  \n",
       "20               76  \n",
       "21               70  \n",
       "22               64  \n",
       "23               57  \n",
       "24               53  \n",
       "25               72  \n",
       "26               62  \n",
       "27               51  \n",
       "28               47  \n",
       "29               40  \n",
       "..              ...  \n",
       "50               44  \n",
       "51               18  \n",
       "52                5  \n",
       "53                4  \n",
       "54               16  \n",
       "55                9  \n",
       "56                1  \n",
       "57                3  \n",
       "58                6  \n",
       "59               14  \n",
       "60               55  \n",
       "61               43  \n",
       "62               34  \n",
       "63               32  \n",
       "64               33  \n",
       "65               50  \n",
       "66               30  \n",
       "67               22  \n",
       "68               19  \n",
       "69               21  \n",
       "70               31  \n",
       "71               36  \n",
       "72               35  \n",
       "73               23  \n",
       "74               28  \n",
       "75               13  \n",
       "76                2  \n",
       "77               15  \n",
       "78               29  \n",
       "79               39  \n",
       "\n",
       "[80 rows x 21 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(clf.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.05, loss='deviance', max_depth=5,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "Best mean cross-validated f1 score: 0.6748738241270634\n"
     ]
    }
   ],
   "source": [
    "print(\"Best estimator:\")\n",
    "print(clf.best_estimator_)\n",
    "print(\"Best mean cross-validated recall score:\", clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importances(model):\n",
    "    fetaure_importances = zip(processed_features, model.feature_importances_)\n",
    "    c = Counter()\n",
    "    for feature, importance in fetaure_importances:\n",
    "        c[feature] += importance\n",
    "    fetaure_importances = c.most_common()\n",
    "    for feature_name, importance in fetaure_importances:\n",
    "        print(\"%s: %f\" % (feature_name, importance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_of_insertions: 0.257560\n",
      "affects_versions: 0.144104\n",
      "summary: 0.138544\n",
      "description: 0.106205\n",
      "components: 0.083791\n",
      "num_of_changed_files: 0.077585\n",
      "num_of_deletions: 0.045057\n",
      "patch_size_mean: 0.029713\n",
      "filepath_contains_test: 0.029428\n",
      "solve_res_diff: 0.016300\n",
      "resolution_time: 0.015206\n",
      "number_of_patches: 0.014953\n",
      "number_of_comments: 0.013229\n",
      "patch_size_rel_variance: 0.008874\n",
      "solve_time: 0.008122\n",
      "patch_size_variance: 0.007462\n",
      "hour_of_commit: 0.002650\n",
      "day_of_week: 0.001216\n"
     ]
    }
   ],
   "source": [
    "get_feature_importances(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.842185128983308"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc_curve(model, X_test, y_test):\n",
    "    y_score = model.predict_proba(X_test)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_score[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    f = plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = roc_auc_curve(clf.best_estimator_, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"auc_roc.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import plot_partial_dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_dependence = plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_partial_dependence(clf.best_estimator_, X, features=[0], feature_names=['number of insertions'], grid_resolution=100, fig=fig_dependence) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig_dependence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on blamed commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval = eval_df.drop('label', axis=1)\n",
    "y_eval = eval_df['label']\n",
    "X_text_summary_eval = text_transformer.fit_transform(eval_df.summary.to_numpy(), y_eval)\n",
    "X_text_description_eval = text_transformer.fit_transform(eval_df.description.to_numpy(), y_eval)\n",
    "# preprocess X\n",
    "X_eval = preprocessor.fit_transform(X_eval, y_eval)\n",
    "X_categorical_eval = multi_value_target_encoding(eval_df, categorical_features, 'label', ';')\n",
    "X_eval = np.hstack((X_eval,X_categorical_eval,X_text_summary_eval, X_text_description_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7374301675977654"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_.score(X_eval, [1]*179)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(clf.best_estimator_, X, y, scoring='accuracy', cv=StratifiedKFold(n_splits=10, shuffle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([11.30826902, 11.70612025, 11.4796412 , 11.59635496, 11.55467176,\n",
       "        10.8740871 , 11.00135684, 11.1822319 , 11.09906101, 11.140306  ]),\n",
       " 'score_time': array([0.00681114, 0.00716186, 0.00719595, 0.00697398, 0.00654221,\n",
       "        0.00683308, 0.00710821, 0.00737095, 0.00654793, 0.00655293]),\n",
       " 'test_score': array([0.76783005, 0.75417299, 0.75872534, 0.75341426, 0.77389985,\n",
       "        0.76479514, 0.78376328, 0.7723824 , 0.78056188, 0.79483283])}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7704378017857787"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_results['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_CRA",
   "language": "python",
   "name": "venv_cra"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
